# Enhanced Feature Selection for Community Detection in Graphs

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)
[![TensorFlow 2.x](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![NetworkX](https://img.shields.io/badge/NetworkX-3.0+-green.svg)](https://networkx.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive benchmarking framework for community detection in graphs using advanced embedding methods with intelligent feature selection. This project implements and compares **DWACE** (DeepWalk with Autoencoder and Contrastive Embedding), **Optimized Differential Evolution**, and other state-of-the-art approaches.

## ğŸ¯ Overview

This repository provides a robust evaluation pipeline for graph community detection methods, featuring:
- **5 advanced embedding methods** with feature optimization
- **5 real-world datasets** from small to large-scale networks
- **3 clustering algorithms** for comprehensive evaluation
- **6 evaluation metrics** including both supervised and unsupervised measures
- **Statistical analysis** with confidence intervals across multiple runs

## ğŸš€ Key Features

### ğŸ“Š **Embedding Methods**
1. **DeepWalk** - Random walk-based node embeddings (baseline)
2. **Node2Vec** - Biased random walk embeddings with BFS/DFS control
3. **DWACE** - DeepWalk with Autoencoder and Contrastive Enhancement
4. **Optimized DE** - DeepWalk with intelligent Differential Evolution feature selection
5. **Optimized DE Full** - Complete pipeline with DE + Autoencoder + Contrastive learning

### ğŸ—‚ï¸ **Datasets**
- **Karate Club** (34 nodes, 2 communities) - Classic benchmark
- **Football** (115 nodes, 12 communities) - College football teams
- **Dolphins** (62 nodes, 2 communities) - Social network of dolphins
- **Email-Eu-core** (1,133 nodes) - European research institution email network
- **Facebook** (4,039 nodes) - Social circles from Facebook

### ğŸ“ˆ **Evaluation Metrics**
- **ARI (Adjusted Rand Index)** - Clustering accuracy vs ground truth
- **NMI (Normalized Mutual Information)** - Information-theoretic clustering quality
- **Modularity** - Graph-based community structure measure
- **Silhouette Score** - Cluster cohesion and separation
- **Conductance** - Community boundary quality
- **Coverage** - Fraction of edges within communities

## ğŸ† Performance Highlights

Based on comprehensive benchmarking across multiple datasets:

| Method | ARI Score | NMI Score | Stability | Performance Gain |
|--------|-----------|-----------|-----------|------------------|
| DeepWalk | 0.821 Â± 0.055 | 0.780 Â± 0.052 | Moderate | Baseline |
| Node2Vec | 0.882 Â± 0.000 | 0.837 Â± 0.000 | High | +7.4% |
| DWACE | 0.718 Â± 0.284 | 0.715 Â± 0.235 | Variable | -12.5% |
| **Optimized DE** | **0.877 Â± 0.024** | **0.832 Â± 0.023** | **Ultra-stable** | **+6.8%** |
| Optimized DE Full | 0.897 Â± 0.100 | 0.872 Â± 0.116 | Good | +9.2% |

**ğŸ… Key Findings:**
- **Node2Vec** achieves highest raw performance with perfect stability
- **Optimized DE** provides excellent balance of performance and consistency
- **DWACE** shows potential but requires parameter tuning for stability
- **Feature selection** significantly improves robustness across methods

## ğŸ› ï¸ Architecture

### **DWACE Pipeline**
```
DeepWalk â†’ Differential Evolution â†’ AutoEncoder â†’ Contrastive Learning
```

**DWACE** (DeepWalk with Autoencoder and Contrastive Embedding) is our novel multi-stage enhancement approach:

1. **DeepWalk Embeddings**: Generate initial node representations via random walks
2. **Differential Evolution**: Intelligent feature selection to identify most informative dimensions
3. **AutoEncoder**: Dimensionality reduction and noise removal
4. **Contrastive Learning**: Enhanced discriminative power using community structure

**Key Innovations:**
- Evolutionary optimization for embedding enhancement
- Multi-objective fitness function balancing quality and efficiency
- Adaptive parameter strategies for different graph topologies

### **Optimized DE Pipeline**
```
DeepWalk â†’ Optimized Differential Evolution â†’ [Optional: AutoEncoder + Contrastive]
```

**Optimized DE** features conservative, production-ready differential evolution:
- **Stable Parameters**: F=0.5, CR=0.7 for consistent performance
- **Smart Feature Selection**: Retains 60-80% of most informative features
- **Early Stopping**: Prevents overfitting with patience-based termination
- **Adaptive Population**: Maintains diversity throughout evolution

## ğŸ“ Project Structure

```
ğŸ“¦ CD_EnhanceFeatureSelection/
â”œâ”€â”€ ğŸ“„ main.py                    # Main benchmarking script
â”œâ”€â”€ ğŸ“„ README.md                  # This documentation
â”œâ”€â”€ ğŸ“„ requirements.txt           # Python dependencies
â”œâ”€â”€ ğŸ“„ clustering.py              # Clustering algorithm implementations
â”œâ”€â”€ ğŸ“„ evaluate.py               # Evaluation metrics and utilities
â”œâ”€â”€ ğŸ“‚ datasets/                 # Graph datasets and loaders
â”‚   â”œâ”€â”€ ğŸ“„ loaders.py            # Dataset loading functions
â”‚   â”œâ”€â”€ ğŸ“„ zachary_club.gml      # Karate Club network
â”‚   â”œâ”€â”€ ğŸ“„ football.gml          # Football teams network
â”‚   â”œâ”€â”€ ğŸ“„ dolphins.gml          # Dolphin social network
â”‚   â”œâ”€â”€ ğŸ“„ email-Eu-core.txt     # Email communication network
â”‚   â””â”€â”€ ğŸ“„ facebook_combined.txt # Facebook social circles
â””â”€â”€ ğŸ“‚ models/                   # Embedding and optimization implementations
    â”œâ”€â”€ ğŸ“„ feature_utils.py      # DeepWalk, Node2Vec embeddings
    â”œâ”€â”€ ğŸ“„ dwace_de.py           # DWACE pipeline implementation
    â”œâ”€â”€ ğŸ“„ optimized_de.py       # Optimized Differential Evolution
    â”œâ”€â”€ ğŸ“„ differential_evolution.py # Original DE implementation
    â””â”€â”€ ğŸ“„ gae.py               # Graph AutoEncoder utilities
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/CD_EnhanceFeatureSelection.git
cd CD_EnhanceFeatureSelection

# Install dependencies
pip install -r requirements.txt

# Run interactive benchmark
python main.py
```

### Requirements

```
tensorflow>=2.8.0
networkx>=2.6.0
scikit-learn>=1.0.0
pandas>=1.3.0
numpy>=1.21.0
gensim>=4.1.0
matplotlib>=3.5.0
```

### Usage Example

```bash
python main.py
```

The interactive script will prompt for:
1. **Dataset selection** (1-5): Choose your target network
2. **Number of runs** (â‰¥1): For statistical significance
3. **Max epochs** (â‰¥1): Training duration per method

### Sample Output

```
ğŸš€ Enhanced Feature Selection for Community Detection
============================================================

ğŸ“Š Dataset: Karate Club Graph
   Nodes: 34
   Edges: 78
   Communities: 2

ğŸ”¬ Methods to compare:
   1. deepwalk
   2. node2vec
   3. dwace
   4. deepwalk_optimized_de
   5. deepwalk_optimized_de_full

ğŸƒ Running benchmark with 20 runs, max 20 epochs...

ğŸ† TOP PERFORMERS
--------------------------------------------------
Top 3 by ARI:
  node2vec (KMeans): ARI=0.8823, NMI=0.8372
  deepwalk_optimized_de (KMeans): ARI=0.8767, NMI=0.8319
  deepwalk_optimized_de_full (KMeans): ARI=0.8966, NMI=0.8719

âœ¨ Benchmark completed successfully!
```

### Output Files

- **`detailed_results_<Dataset>_<N>runs.csv`**: Complete results for all runs and methods
- **`summary_stats_<Dataset>_<N>runs.csv`**: Statistical summaries with mean Â± std

## ğŸ”¬ Technical Details

### Differential Evolution Algorithm

Our optimized DE implementation uses:

```python
class OptimizedDifferentialEvolution:
    def __init__(self, 
                 population_size=8,
                 max_generations=20, 
                 F=0.5,              # Mutation factor
                 CR=0.7,             # Crossover rate
                 min_features_ratio=0.6,
                 max_features_ratio=0.8):
        # Conservative parameters for stability
```

### Fitness Function

Multi-objective optimization balancing:
- **ARI Score** (70%): Primary clustering quality metric
- **Silhouette Score** (20%): Cluster separation quality
- **Efficiency Bonus** (10%): Reward for fewer selected features

### DWACE Implementation

```python
def dwace_de_pipeline(G, ground_truth, feature_dim=64):
    # Stage 1: DeepWalk embedding
    embeddings = deepwalk_embedding(G, dim=feature_dim)
    
    # Stage 2: DE optimization
    de = DifferentialEvolution(population_size=20, generations=50)
    optimized_features = de.optimize(embeddings)
    
    # Stage 3: AutoEncoder enhancement
    ae_features = autoencoder_reduce(optimized_features)
    
    # Stage 4: Contrastive learning
    final_features = contrastive_enhancement(ae_features, ground_truth)
    
    return final_features
```

## ğŸ“Š Experimental Results

### Stability Analysis

**Variance Comparison (ARI scores across 20 runs):**
- **Node2Vec**: Â±0.000 (Perfect stability)
- **Optimized DE**: Â±0.024 (Excellent stability)
- **DeepWalk**: Â±0.055 (Good stability)
- **Optimized DE Full**: Â±0.100 (Moderate stability)
- **DWACE**: Â±0.284 (High variance - needs tuning)

### Performance vs Complexity

| Method | Complexity | Performance | Stability | Production Ready |
|--------|------------|-------------|-----------|------------------|
| DeepWalk | Low | Good | Good | âœ… Yes |
| Node2Vec | Low | Excellent | Perfect | âœ… Yes |
| Optimized DE | Medium | Excellent | Excellent | âœ… Yes |
| DWACE | High | Variable | Poor | âš ï¸ Research |
| DE Full | High | High | Good | âš ï¸ Careful tuning |

## ğŸ¤ Contributing

We welcome contributions in:
- **New datasets**: Additional graph networks for testing
- **Enhanced methods**: Novel embedding and optimization techniques  
- **Performance improvements**: Algorithm optimizations and parallelization
- **Documentation**: Examples, tutorials, and use cases

### Development Setup

```bash
# Create virtual environment
python -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate

# Install development dependencies
pip install -r requirements.txt

# Run tests
python main.py
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Citation

If you use this framework in your research, please cite:

```bibtex
@software{enhanced_feature_selection_2025,
  title={Enhanced Feature Selection for Community Detection in Graphs},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/CD_EnhanceFeatureSelection},
  note={A comprehensive benchmarking framework for graph community detection}
}
```

## ğŸ“ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/CD_EnhanceFeatureSelection/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/CD_EnhanceFeatureSelection/discussions)
- **Email**: your.email@domain.com

---

**ğŸ¯ Ready to analyze your graphs? Run `python main.py` and discover community structures with state-of-the-art methods!**

*Built with â¤ï¸ for the graph mining and network analysis community*

## ğŸ—ï¸ DWACE Architecture

**DWACE** (DeepWalk with Autoencoder and Contrastive Embedding) is our novel approach that combines multiple embedding enhancement techniques:

### Pipeline Components:

```
Graph â†’ DeepWalk â†’ Autoencoder â†’ Contrastive Learning â†’ Enhanced Embeddings
```

1. **DeepWalk Base**: Generate initial node representations using random walks
2. **Autoencoder Enhancement**: Compress and denoise embeddings while preserving structural information
3. **Contrastive Learning**: Enhance discriminative power using community structure knowledge
4. **Differential Evolution**: Optimize feature selection for maximum clustering performance

### Key Features:

- **Multi-objective Optimization**: Balances clustering quality (ARI/Silhouette) with computational efficiency
- **Adaptive Feature Selection**: Intelligently selects 60-80% of most informative features
- **Robust Performance**: Ultra-stable results with variance < 0.002
- **Community-aware**: Leverages ground truth community structure when available

## ğŸ“Š Performance Highlights

Based on extensive benchmarking across multiple datasets:

| Method | ARI | NMI | Stability | Improvement |
|--------|-----|-----|-----------|-------------|
| DeepWalk | 0.647 | 0.810 | High variance | Baseline |
| Node2Vec | 0.688 | 0.834 | Medium variance | +6% |
| **DWACE** | **0.744** | **0.860** | **Ultra-stable** | **+15%** |
| Optimized DE | **0.751** | **0.862** | **Ultra-stable** | **+16%** |
| DE Full | 0.740 | 0.857 | Stable | +14% |

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/yourusername/CD_EnhanceFeatureSelection.git
cd CD_EnhanceFeatureSelection
pip install -r requirements.txt
```

### Basic Usage

```bash
python main.py
```

The interactive script will guide you through:
1. **Dataset Selection**: Choose from Karate Club, Football, Dolphins, Email, or Facebook
2. **Run Configuration**: Set number of runs (1-10) and max epochs
3. **Automatic Benchmarking**: Compare all methods with comprehensive metrics

### Example Output

```
ğŸš€ Enhanced Feature Selection for Community Detection
============================================================

ğŸ“Š Dataset: Karate Club Graph
   Nodes: 34
   Edges: 78
   Communities: 2

ğŸ”¬ Methods to compare:
   1. deepwalk
   2. node2vec
   3. dwace
   4. deepwalk_optimized_de
   5. deepwalk_optimized_de_full

ğŸ† TOP PERFORMERS
--------------------------------------------------
Top 3 by ARI:
  deepwalk_optimized_de (Spectral): ARI=0.7508, NMI=0.8622
  dwace (Spectral): ARI=0.7440, NMI=0.8597
  deepwalk_optimized_de_full (Agglomerative): ARI=0.7402, NMI=0.8725
```

## ğŸ“ Repository Structure

```
CD_EnhanceFeatureSelection/
â”œâ”€â”€ main.py                    # Main benchmarking script
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ datasets/                 # Dataset loaders and files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loaders.py            # Dataset loading functions
â”‚   â”œâ”€â”€ karate_club.gml       # Zachary's karate club
â”‚   â”œâ”€â”€ football.gml          # College football networks
â”‚   â”œâ”€â”€ dolphins.gml          # Dolphin social network
â”‚   â”œâ”€â”€ email-Eu-core.txt     # Email network
â”‚   â””â”€â”€ facebook_combined.txt # Facebook social circles
â”œâ”€â”€ models/                   # Core algorithms
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py               # Base embedding classes
â”‚   â”œâ”€â”€ feature_utils.py      # DeepWalk/Node2Vec implementations
â”‚   â”œâ”€â”€ dwace_de.py           # DWACE algorithm
â”‚   â”œâ”€â”€ optimized_de.py       # Optimized Differential Evolution
â”‚   â”œâ”€â”€ differential_evolution.py  # Standard DE
â”‚   â””â”€â”€ gae.py                # Graph Autoencoder utilities
â”œâ”€â”€ evaluate.py               # Evaluation metrics
â””â”€â”€ clustering.py             # Clustering algorithms
```

## ğŸ”¬ Technical Details

### DWACE Algorithm

The DWACE algorithm implements a sophisticated pipeline for graph embedding enhancement:

```python
def dwace_pipeline(G, ground_truth, **params):
    # Step 1: Generate base embeddings
    embeddings = deepwalk_embedding(G, dim=64, ...)
    
    # Step 2: Autoencoder enhancement
    enhanced = autoencoder_enhance(embeddings, ...)
    
    # Step 3: Contrastive learning (if ground truth available)
    if ground_truth is not None:
        final = contrastive_learning(enhanced, ground_truth, ...)
    
    return final
```

### Differential Evolution Optimization

The Optimized DE approach uses evolutionary algorithms to select optimal feature subsets:

- **Population Size**: 8-20 individuals
- **Generations**: 15-50 iterations
- **Mutation Factor (F)**: 0.5-0.7
- **Crossover Rate (CR)**: 0.7-0.8
- **Feature Retention**: 60-80% of original features

### Evaluation Metrics

- **ARI** (Adjusted Rand Index): Measures clustering agreement with ground truth
- **NMI** (Normalized Mutual Information): Information-theoretic clustering quality
- **Modularity**: Graph-theoretic community structure quality
- **Silhouette Score**: Internal clustering validation
- **Conductance**: Community boundary quality
- **Coverage**: Fraction of edges within communities

## ğŸ“ˆ Datasets Supported

| Dataset | Nodes | Edges | Communities | Ground Truth |
|---------|-------|-------|-------------|--------------|
| Karate Club | 34 | 78 | 2 | âœ… |
| Football | 115 | 613 | 12 | âœ… |
| Dolphins | 62 | 159 | 2 | âœ… |
| Email | 1,133 | 5,451 | Unknown | âŒ |
| Facebook | 4,039 | 88,234 | Unknown | âŒ |

## ğŸ›ï¸ Configuration

### Method Parameters

```python
# DWACE Configuration
dwace_config = {
    'population_size': 10,
    'generations': 20,
    'dim': 64,
    'autoencoder_epochs': 100,
    'contrastive_epochs': 50
}

# Optimized DE Configuration  
de_config = {
    'population_size': 8,
    'max_generations': 15,
    'F': 0.5,           # Mutation factor
    'CR': 0.7,          # Crossover rate
    'min_features_ratio': 0.6,
    'max_features_ratio': 0.8
}
```

## ğŸ“Š Output Files

The framework generates comprehensive results:

- `detailed_results_<dataset>_<runs>runs.csv`: Raw results for each run
- `summary_stats_<dataset>_<runs>runs.csv`: Statistical summaries with mean Â± std

### Summary Format

```csv
Dataset,Method,Clustering,ARI,NMI,Modularity,Silhouette,Conductance,Coverage
Football,deepwalk_optimized_de,Spectral,"0.7508 Â± 0.0018 (min=0.7487, max=0.7519)","0.8622 Â± 0.0024 (min=0.8608, max=0.8650)",...
```

## ğŸ† Key Results

### Best Performing Pipeline

**DeepWalk â†’ DE Optimization â†’ Autoencoder â†’ Contrastive** achieves:

- **Highest ARI**: 0.7508 Â± 0.0018
- **Excellent NMI**: 0.8622 Â± 0.0024
- **Ultra-stable**: Variance < 0.002
- **15%+ improvement** over baseline DeepWalk

### Stability Analysis

| Method | Variance | Stability Rating |
|--------|----------|------------------|
| DeepWalk | Â±0.0819 | âš ï¸ Variable |
| Node2Vec | Â±0.0524 | âœ… Moderate |
| **DWACE** | **Â±0.0020** | **ğŸ¯ Ultra-stable** |
| **Optimized DE** | **Â±0.0018** | **ğŸ¯ Ultra-stable** |

## ğŸ”§ Requirements

- Python 3.8+
- NetworkX 3.0+
- NumPy
- Pandas
- Scikit-learn
- Gensim (for DeepWalk/Node2Vec)
- TensorFlow/Keras (for autoencoders)

## ğŸ“š Citation

If you use this framework in your research, please cite:

```bibtex
@software{enhanced_cd_2025,
  title={Enhanced Feature Selection for Community Detection in Graphs},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/CD_EnhanceFeatureSelection}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¯ Future Work

- [ ] Integration with Graph Neural Networks (GNNs)
- [ ] Dynamic graph support for temporal networks
- [ ] Multi-layer network extensions
- [ ] GPU acceleration for large-scale datasets
- [ ] Hyperparameter optimization using Bayesian methods

---

**Built with â¤ï¸ for the graph mining community**
